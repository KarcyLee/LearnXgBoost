> 本节主要讲Learner
>
> [XGBoost解析系列--源码主流程](https://blog.csdn.net/matrix_zzl/article/details/78699605)

# 1. learner.h

基本结构

```
|--Learner
	 |-- std::unique_ptr<Learner> learner(new Learner::Create(cache_mats))
	 |-- learner.Configure(configs)
	 |-- for (int iter = 0; iter < max_iter; ++iter) 
	 		{
	 			|-- learner->UpdateOneIter(iter, train_mat)
	 			|-- learner->EvalOneIter(iter, data_sets, data_names)
	 		}	
```

核心定义了三个句柄

```
  /*! \brief objective function */
  std::unique_ptr<ObjFunction> obj_; // 目标函数
  /*! \brief The gradient booster used by the model*/
  std::unique_ptr<GradientBooster> gbm_; 
  /*! \brief The evaluation metrics used to evaluate the model. */
  std::vector<std::unique_ptr<Metric> > metrics_;
```

gbm_ 属于 Class GradientBoost ,  是一个抽象类，它定义了 Gradient Boost 的抽象接口。其派生出的两个类 Class GBTree 和 Class GBLinear 分别对应着配置文件里面的参数"gbtree"和"gblinear"

- Class GBTree 主要使用的回归树作为其弱分类器
-  Class GBLinear 使用的是线性回归或逻辑回归作为其弱分类器

obj_ 属于class ObjFunction， 目标函数/损失函数的抽象接口类，在src/objective下有多种实现：

- HingeObj
- multicalss_obj
  - SoftmaxMultiClassObj
- rank_obj
  - LambdaRankObj
  - PairwiseRankObj
  - LambdaRankObjNDCG
  - LambdaRankObjMAP
- regression_obj
  - RegLossObj
  - PoissonRegression
  - CoxRegression
  - TweedieRegression 

metrics_ 属于抽象类Metric，主要实现评价函数的功能，在src/mectirc下有多种实现，主要分为三类：

- Multiclass_metric多分类
- Rank_metric 排序
- Elementwise_metric 元素评价

learner.h

```c++

class Learner : public rabit::Serializable {
 public:
  ~Learner() override = default;
  virtual void Configure() = 0;
  void Load(dmlc::Stream* fi) override = 0;
  void Save(dmlc::Stream* fo) const override = 0;
  /*!
   * \brief update the model for one iteration
   *  With the specified objective function.
   * \param iter current iteration number
   * \param train reference to the data matrix.
   */
  virtual void UpdateOneIter(int iter, DMatrix* train) = 0;
  /*!
   * \brief Do customized gradient boosting with in_gpair.
   *  in_gair can be mutated after this call.
   * \param iter current iteration number
   * \param train reference to the data matrix.
   * \param in_gpair The input gradient statistics.
   */
  virtual void BoostOneIter(int iter,
                            DMatrix* train,
                            HostDeviceVector<GradientPair>* in_gpair) = 0;
  /*!
   * \brief evaluate the model for specific iteration using the configured metrics.
   * \param iter iteration number
   * \param data_sets datasets to be evaluated.
   * \param data_names name of each dataset
   * \return a string corresponding to the evaluation result
   */
  virtual std::string EvalOneIter(int iter,
                                  const std::vector<DMatrix*>& data_sets,
                                  const std::vector<std::string>& data_names) = 0;
  /*!
   * \brief get prediction given the model.
   * \param data input data
   * \param output_margin whether to only predict margin value instead of transformed prediction
   * \param out_preds output vector that stores the prediction
   * \param ntree_limit limit number of trees used for boosted tree
   *   predictor, when it equals 0, this means we are using all the trees
   * \param pred_leaf whether to only predict the leaf index of each tree in a boosted tree predictor
   * \param pred_contribs whether to only predict the feature contributions
   * \param approx_contribs whether to approximate the feature contributions for speed
   * \param pred_interactions whether to compute the feature pair contributions
   */
  virtual void Predict(DMatrix* data,
                       bool output_margin,
                       HostDeviceVector<bst_float> *out_preds,
                       unsigned ntree_limit = 0,
                       bool pred_leaf = false,
                       bool pred_contribs = false,
                       bool approx_contribs = false,
                       bool pred_interactions = false) = 0;
  /*!
   * \brief Set multiple parameters at once.
   * \param args parameters.
   */
  virtual void SetParams(Args const& args) = 0;
  /*!
   * \brief Set parameter for booster
   *  The property will NOT be saved along with booster
   * \param key   The key of parameter
   * \param value The value of parameter
   */
  virtual void SetParam(const std::string& key, const std::string& value) = 0;

  /*!
   * \brief Set additional attribute to the Booster.
   *
   *  The property will be saved along the booster.
   *
   * \param key The key of the property.
   * \param value The value of the property.
   */
  virtual void SetAttr(const std::string& key, const std::string& value) = 0;
  /*!
   * \brief Get attribute from the booster.
   *  The property will be saved along the booster.
   * \param key The key of the attribute.
   * \param out The output value.
   * \return Whether the key exists among booster's attributes.
   */
  virtual bool GetAttr(const std::string& key, std::string* out) const = 0;
  /*!
   * \brief Delete an attribute from the booster.
   * \param key The key of the attribute.
   * \return Whether the key was found among booster's attributes.
   */
  virtual bool DelAttr(const std::string& key) = 0;
  /*!
   * \brief Get a vector of attribute names from the booster.
   * \return vector of attribute name strings.
   */
  virtual std::vector<std::string> GetAttrNames() const = 0;
  /*!
   * \return whether the model allow lazy checkpoint in rabit.
   */
  bool AllowLazyCheckPoint() const;

  virtual std::vector<std::string> DumpModel(const FeatureMap& fmap, bool with_stats, std::string format) const = 0;
  /*!
   * \brief Create a new instance of learner.
   * \param cache_data The matrix to cache the prediction.
   * \return Created learner.
   */
  static Learner* Create(const std::vector<std::shared_ptr<DMatrix> >& cache_data);

  virtual GenericParameter const& GetGenericParameter() const = 0;
  /*!
   * \brief Get configuration arguments currently stored by the learner
   * \return Key-value pairs representing configuration arguments
   */
  virtual const std::map<std::string, std::string>& GetConfigurationArguments() const = 0;

 protected:
  /*! \brief internal base score of the model */
  bst_float base_score_;
  /*! \brief objective function */
  std::unique_ptr<ObjFunction> obj_;
  /*! \brief The gradient booster used by the model*/
  std::unique_ptr<GradientBooster> gbm_;
  /*! \brief The evaluation metrics used to evaluate the model. */
  std::vector<std::unique_ptr<Metric> > metrics_;
  /*! \brief Training parameter. */
  GenericParameter generic_param_;
};

```

# 2.  learner.cc

Learner类定义了三个核心句柄gbm_(子模型tree/linear)，obj_(损失函数)，metrics_(评价函数)

LearnerImpl 类 实现了Learner接口。

## Learner::Create()

```
// Learn 类中，静态create函数，实现工厂方法。
 static Learner* Create(const std::vector<std::shared_ptr<DMatrix> >& cache_data);

// LearnerImpl 类中，利用工厂方法构建。
Learner* Learner::Create(
    const std::vector<std::shared_ptr<DMatrix> >& cache_data) {
  return new LearnerImpl(cache_data);
}

// 使用时， 工厂方法
std::unique_ptr<Learner> learner(new Learner::Create(cache_mats))
```

## Learner::Configure()

```
|-- Learner::Configure()
		|-- InitAllowUnknown() // 初始化参数
		|-- ConfigureNumFeatures() // 设置num_features. gbm必须。
		|-- ConfigureObjective() // 
		|-- ConfigureGBM()
		|-- ConfigureMetrics()
```

## Learner::UpdateOneIter()

在每次迭代过程中，GetGradient() 获取目标函数的一阶导和二阶导，最后 DoBoost() 执行 Boost 操作生成一棵回归树。

```
|-- Learner::UpdateOneIter()
		// 初始化并校验
		|-- Configure()
		|-- CheckDataSplitMode()
    |-- ValidateDMatrix(train)
    // 预测训练数据
		|-- PredictRaw(train, &preds_[train])
				|-- gbm_->PredictBatch()
		// 求解梯度向量，包括一阶导和二阶导
		|-- obj_ -> GetGradient(preds_[train], train->Info(), iter, &gpair_)
		// 开始建树
		|-- gbm_ -> DoBoost(train, &gpair_, obj_.get())
```

## Learner::EvalOneIter

支持对多个评价数据集分别评价，对每个数据集，先进行预测（PredictRaw()），计算损失函数（obj_->EvalTransform()），再调metrics_中的各个评价器，输出结果

```
|-- Learner::EvalOneIter()
		// 初始化并校验
		|-- Configure()
		// 如果没有设置评估方式（metrics）时，利用工厂方式构建一个metric
		|--Metric::Create(obj_->DefaultEvalMetric(), &generic_param_)
    // 遍历每个样本进行评估
    |-- for (size_t i = 0; i < data_sets.size(); ++i) 
    {
    		|-- dmat = data_sets[i]
    		// 校验
    		|-- ValidateDMatrix(dmat)
    		// 预测
    		|-- PredictRaw(data_sets[i], &preds_[dmat])
    		// ？？ todo
    		|-- >obj_ -> EvalTransform(&preds_[dmat])
    		// 遍历每个度量方式
    		|--  for (auto& ev : metrics_) 
    		{
       			ev->Eval(preds_[dmat], ...);
      	}
    }
    
```

## Learner::BoostOneIter

```
// Do customized gradient boosting with in_gpair
|-- Learner::BoostOneIter()
		// 初始化并校验
		|-- Configure()
		|-- CheckDataSplitMode();
    |-- ValidateDMatrix(train);
		|-- gbm_->DoBoost(train, in_gpair);
```

## Learner::PredictRaw()

PredictRaw对预测数据进行预测，后续根据预测值才能计算一阶梯度与二阶梯度。

```
|-- Learner::PredictRaw()
		|-- ValidateDMatrix()
		// 利用CSR行遍历访问能力，批次预测实例数据
		|-- gbm_->PredictBatch(data, out_preds, ntree_limit)
```

gbm_框架配置预测器对象predictor，要么是CPUPredictor或者GPUPredictor，默认配置为CPUPredictor.

PredictRaw过程直接调用PredictBatch。 PredictBatch是个通用接口。训练过程只有第一次执行调用PredictBatch中的PredLoopInternal，而且第一次调用GBTreeModel对象内的回归树为空，不执行回归树的预测，第一次也就只有base_margin值。纯粹的预测任务中，调用PredictBatch，才会执行回归树的预测过程。

